{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"Have you used the new version of my model?\", \"spans\": [{\"start\": 36, \"end\": 41, \"token_start\": 8, \"token_end\": 8, \"label\": \"SKILL\"}], \"tokens\": [{\"text\": \"Have\", \"start\": 0, \"end\": 4, \"id\": 0}, {\"text\": \"you\", \"start\": 5, \"end\": 8, \"id\": 1}, {\"text\": \"used\", \"start\": 9, \"end\": 13, \"id\": 2}, {\"text\": \"the\", \"start\": 14, \"end\": 17, \"id\": 3}, {\"text\": \"new\", \"start\": 18, \"end\": 21, \"id\": 4}, {\"text\": \"version\", \"start\": 22, \"end\": 29, \"id\": 5}, {\"text\": \"of\", \"start\": 30, \"end\": 32, \"id\": 6}, {\"text\": \"my\", \"start\": 33, \"end\": 35, \"id\": 7}, {\"text\": \"model\", \"start\": 36, \"end\": 41, \"id\": 8}, {\"text\": \"?\", \"start\": 41, \"end\": 42, \"id\": 9}]},\n",
      "{\"text\": \"I'd like to work as an actor or model if possible.\", \"spans\": [{\"text\": \"actor\", \"start\": 23, \"end\": 28, \"token_start\": 7, \"token_end\": 7, \"label\": \"JOB_ROLE\"}, {\"text\": \"model\", \"start\": 32, \"end\": 37, \"token_start\": 9, \"token_end\": 9, \"label\": \"JOB_ROLE\"}], \"tokens\": [{\"text\": \"I\", \"start\": 0, \"end\": 1, \"id\": 0}, {\"text\": \"'d\", \"start\": 1, \"end\": 3, \"id\": 1}, {\"text\": \"like\", \"start\": 4, \"end\": 8, \"id\": 2}, {\"text\": \"to\", \"start\": 9, \"end\": 11, \"id\": 3}, {\"text\": \"work\", \"start\": 12, \"end\": 16, \"id\": 4}, {\"text\": \"as\", \"start\": 17, \"end\": 19, \"id\": 5}, {\"text\": \"an\", \"start\": 20, \"end\": 22, \"id\": 6}, {\"text\": \"actor\", \"start\": 23, \"end\": 28, \"id\": 7}, {\"text\": \"or\", \"start\": 29, \"end\": 31, \"id\": 8}, {\"text\": \"model\", \"start\": 32, \"end\": 37, \"id\": 9}, {\"text\": \"if\", \"start\": 38, \"end\": 40, \"id\": 10}, {\"text\": \"possible\", \"start\": 41, \"end\": 49, \"id\": 11}, {\"text\": \".\", \"start\": 49, \"end\": 50, \"id\": 12}]},\n",
      "{\"text\": \"We are looking for a Software Development Engineer who has solid coding skills, a strong machine learning background, and is passionate about developing new AI products.\", \"tokens\": [{\"text\": \"We\", \"start\": 0, \"end\": 2, \"id\": 0}, {\"text\": \"are\", \"start\": 3, \"end\": 6, \"id\": 1}, {\"text\": \"looking\", \"start\": 7, \"end\": 14, \"id\": 2}, {\"text\": \"for\", \"start\": 15, \"end\": 18, \"id\": 3}, {\"text\": \"a\", \"start\": 19, \"end\": 20, \"id\": 4}, {\"text\": \"Software\", \"start\": 21, \"end\": 29, \"id\": 5}, {\"text\": \"Development\", \"start\": 30, \"end\": 41, \"id\": 6}, {\"text\": \"Engineer\", \"start\": 42, \"end\": 50, \"id\": 7}, {\"text\": \"who\", \"start\": 51, \"end\": 54, \"id\": 8}, {\"text\": \"has\", \"start\": 55, \"end\": 58, \"id\": 9}, {\"text\": \"solid\", \"start\": 59, \"end\": 64, \"id\": 10}, {\"text\": \"coding\", \"start\": 65, \"end\": 71, \"id\": 11}, {\"text\": \"skills\", \"start\": 72, \"end\": 78, \"id\": 12}, {\"text\": \",\", \"start\": 78, \"end\": 79, \"id\": 13}, {\"text\": \"a\", \"start\": 80, \"end\": 81, \"id\": 14}, {\"text\": \"strong\", \"start\": 82, \"end\": 88, \"id\": 15}, {\"text\": \"machine\", \"start\": 89, \"end\": 96, \"id\": 16}, {\"text\": \"learning\", \"start\": 97, \"end\": 105, \"id\": 17}, {\"text\": \"background\", \"start\": 106, \"end\": 116, \"id\": 18}, {\"text\": \",\", \"start\": 116, \"end\": 117, \"id\": 19}, {\"text\": \"and\", \"start\": 118, \"end\": 121, \"id\": 20}, {\"text\": \"is\", \"start\": 122, \"end\": 124, \"id\": 21}, {\"text\": \"passionate\", \"start\": 125, \"end\": 135, \"id\": 22}, {\"text\": \"about\", \"start\": 136, \"end\": 141, \"id\": 23}, {\"text\": \"developing\", \"start\": 142, \"end\": 152, \"id\": 24}, {\"text\": \"new\", \"start\": 153, \"end\": 156, \"id\": 25}, {\"text\": \"AI\", \"start\": 157, \"end\": 159, \"id\": 26}, {\"text\": \"products\", \"start\": 160, \"end\": 168, \"id\": 27}, {\"text\": \".\", \"start\": 168, \"end\": 169, \"id\": 28}], \"spans\": [{\"start\": 21, \"end\": 50, \"token_start\": 5, \"token_end\": 7, \"label\": \"SKILL\"}, {\"start\": 65, \"end\": 71, \"token_start\": 11, \"token_end\": 11, \"label\": \"SKILL\"}, {\"start\": 89, \"end\": 105, \"token_start\": 16, \"token_end\": 17, \"label\": \"SKILL\"}, {\"start\": 142, \"end\": 152, \"token_start\": 24, \"token_end\": 24, \"label\": \"SKILL\"}, {\"start\": 157, \"end\": 159, \"token_start\": 26, \"token_end\": 26, \"label\": \"SKILL\"}]},\n",
      "{\"text\": \"Responsibilities As a SOFTWARE DEVELOPMENT ENGINEER II you will work / collaborate with other talented engineers to build features and technologies that will affect millions of your fellow developers in the community.\", \"tokens\": [{\"text\": \"Responsibilities\", \"start\": 0, \"end\": 16, \"id\": 0}, {\"text\": \"As\", \"start\": 17, \"end\": 19, \"id\": 1}, {\"text\": \"a\", \"start\": 20, \"end\": 21, \"id\": 2}, {\"text\": \"SOFTWARE\", \"start\": 22, \"end\": 30, \"id\": 3}, {\"text\": \"DEVELOPMENT\", \"start\": 31, \"end\": 42, \"id\": 4}, {\"text\": \"ENGINEER\", \"start\": 43, \"end\": 51, \"id\": 5}, {\"text\": \"II\", \"start\": 52, \"end\": 54, \"id\": 6}, {\"text\": \"you\", \"start\": 55, \"end\": 58, \"id\": 7}, {\"text\": \"will\", \"start\": 59, \"end\": 63, \"id\": 8}, {\"text\": \"work\", \"start\": 64, \"end\": 68, \"id\": 9}, {\"text\": \"/\", \"start\": 69, \"end\": 70, \"id\": 10}, {\"text\": \"collaborate\", \"start\": 71, \"end\": 82, \"id\": 11}, {\"text\": \"with\", \"start\": 83, \"end\": 87, \"id\": 12}, {\"text\": \"other\", \"start\": 88, \"end\": 93, \"id\": 13}, {\"text\": \"talented\", \"start\": 94, \"end\": 102, \"id\": 14}, {\"text\": \"engineers\", \"start\": 103, \"end\": 112, \"id\": 15}, {\"text\": \"to\", \"start\": 113, \"end\": 115, \"id\": 16}, {\"text\": \"build\", \"start\": 116, \"end\": 121, \"id\": 17}, {\"text\": \"features\", \"start\": 122, \"end\": 130, \"id\": 18}, {\"text\": \"and\", \"start\": 131, \"end\": 134, \"id\": 19}, {\"text\": \"technologies\", \"start\": 135, \"end\": 147, \"id\": 20}, {\"text\": \"that\", \"start\": 148, \"end\": 152, \"id\": 21}, {\"text\": \"will\", \"start\": 153, \"end\": 157, \"id\": 22}, {\"text\": \"affect\", \"start\": 158, \"end\": 164, \"id\": 23}, {\"text\": \"millions\", \"start\": 165, \"end\": 173, \"id\": 24}, {\"text\": \"of\", \"start\": 174, \"end\": 176, \"id\": 25}, {\"text\": \"your\", \"start\": 177, \"end\": 181, \"id\": 26}, {\"text\": \"fellow\", \"start\": 182, \"end\": 188, \"id\": 27}, {\"text\": \"developers\", \"start\": 189, \"end\": 199, \"id\": 28}, {\"text\": \"in\", \"start\": 200, \"end\": 202, \"id\": 29}, {\"text\": \"the\", \"start\": 203, \"end\": 206, \"id\": 30}, {\"text\": \"community\", \"start\": 207, \"end\": 216, \"id\": 31}, {\"text\": \".\", \"start\": 216, \"end\": 217, \"id\": 32}], \"spans\": [{\"start\": 22, \"end\": 51, \"token_start\": 3, \"token_end\": 5, \"label\": \"JOB_ROLE\"}, {\"start\": 71, \"end\": 82, \"token_start\": 11, \"token_end\": 11, \"label\": \"SKILL\"}, {\"start\": 103, \"end\": 112, \"token_start\": 15, \"token_end\": 15, \"label\": \"JOB_ROLE\"}, {\"start\": 135, \"end\": 147, \"token_start\": 20, \"token_end\": 20, \"label\": \"SKILL\"}, {\"start\": 189, \"end\": 199, \"token_start\": 28, \"token_end\": 28, \"label\": \"JOB_ROLE\"}]},\n"
     ]
    }
   ],
   "source": [
    "raw_examples = [\n",
    "    {\"text\":\"Have you used the new version of my model?\",\"spans\":[{\"start\":36,\"end\":41,\"token_start\":8,\"token_end\":8,\"label\":\"SKILL\"}],\"_input_hash\":1798863398,\"_task_hash\":1273875979,\"tokens\":[{\"text\":\"Have\",\"start\":0,\"end\":4,\"id\":0},{\"text\":\"you\",\"start\":5,\"end\":8,\"id\":1},{\"text\":\"used\",\"start\":9,\"end\":13,\"id\":2},{\"text\":\"the\",\"start\":14,\"end\":17,\"id\":3},{\"text\":\"new\",\"start\":18,\"end\":21,\"id\":4},{\"text\":\"version\",\"start\":22,\"end\":29,\"id\":5},{\"text\":\"of\",\"start\":30,\"end\":32,\"id\":6},{\"text\":\"my\",\"start\":33,\"end\":35,\"id\":7},{\"text\":\"model\",\"start\":36,\"end\":41,\"id\":8},{\"text\":\"?\",\"start\":41,\"end\":42,\"id\":9}],\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\"},\n",
    "    {\"text\":\"I'd like to work as an actor or model if possible.\",\"spans\":[{\"text\":\"actor\",\"start\":23,\"end\":28,\"token_start\":7,\"token_end\":7,\"label\":\"JOB_ROLE\"},{\"text\":\"model\",\"start\":32,\"end\":37,\"token_start\":9,\"token_end\":9,\"label\":\"JOB_ROLE\"}],\"_input_hash\":895552771,\"_task_hash\":-936257555,\"tokens\":[{\"text\":\"I\",\"start\":0,\"end\":1,\"id\":0},{\"text\":\"'d\",\"start\":1,\"end\":3,\"id\":1},{\"text\":\"like\",\"start\":4,\"end\":8,\"id\":2},{\"text\":\"to\",\"start\":9,\"end\":11,\"id\":3},{\"text\":\"work\",\"start\":12,\"end\":16,\"id\":4},{\"text\":\"as\",\"start\":17,\"end\":19,\"id\":5},{\"text\":\"an\",\"start\":20,\"end\":22,\"id\":6},{\"text\":\"actor\",\"start\":23,\"end\":28,\"id\":7},{\"text\":\"or\",\"start\":29,\"end\":31,\"id\":8},{\"text\":\"model\",\"start\":32,\"end\":37,\"id\":9},{\"text\":\"if\",\"start\":38,\"end\":40,\"id\":10},{\"text\":\"possible\",\"start\":41,\"end\":49,\"id\":11},{\"text\":\".\",\"start\":49,\"end\":50,\"id\":12}],\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\"},\n",
    "    {\"text\":\"We are looking for a Software Development Engineer who has solid coding skills, a strong machine learning background, and is passionate about developing new AI products.\",\"meta\":{\"id\":\"599073\",\"category\":\"Engineering\",\"subCategory\":\"Data & Applied Sciences\"},\"_input_hash\":-275722772,\"_task_hash\":868828486,\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\",\"dataset\":1,\"tokens\":[{\"text\":\"We\",\"start\":0,\"end\":2,\"id\":0},{\"text\":\"are\",\"start\":3,\"end\":6,\"id\":1},{\"text\":\"looking\",\"start\":7,\"end\":14,\"id\":2},{\"text\":\"for\",\"start\":15,\"end\":18,\"id\":3},{\"text\":\"a\",\"start\":19,\"end\":20,\"id\":4},{\"text\":\"Software\",\"start\":21,\"end\":29,\"id\":5},{\"text\":\"Development\",\"start\":30,\"end\":41,\"id\":6},{\"text\":\"Engineer\",\"start\":42,\"end\":50,\"id\":7},{\"text\":\"who\",\"start\":51,\"end\":54,\"id\":8},{\"text\":\"has\",\"start\":55,\"end\":58,\"id\":9},{\"text\":\"solid\",\"start\":59,\"end\":64,\"id\":10},{\"text\":\"coding\",\"start\":65,\"end\":71,\"id\":11},{\"text\":\"skills\",\"start\":72,\"end\":78,\"id\":12},{\"text\":\",\",\"start\":78,\"end\":79,\"id\":13},{\"text\":\"a\",\"start\":80,\"end\":81,\"id\":14},{\"text\":\"strong\",\"start\":82,\"end\":88,\"id\":15},{\"text\":\"machine\",\"start\":89,\"end\":96,\"id\":16},{\"text\":\"learning\",\"start\":97,\"end\":105,\"id\":17},{\"text\":\"background\",\"start\":106,\"end\":116,\"id\":18},{\"text\":\",\",\"start\":116,\"end\":117,\"id\":19},{\"text\":\"and\",\"start\":118,\"end\":121,\"id\":20},{\"text\":\"is\",\"start\":122,\"end\":124,\"id\":21},{\"text\":\"passionate\",\"start\":125,\"end\":135,\"id\":22},{\"text\":\"about\",\"start\":136,\"end\":141,\"id\":23},{\"text\":\"developing\",\"start\":142,\"end\":152,\"id\":24},{\"text\":\"new\",\"start\":153,\"end\":156,\"id\":25},{\"text\":\"AI\",\"start\":157,\"end\":159,\"id\":26},{\"text\":\"products\",\"start\":160,\"end\":168,\"id\":27},{\"text\":\".\",\"start\":168,\"end\":169,\"id\":28}],\"spans\":[{\"start\":21,\"end\":50,\"token_start\":5,\"token_end\":7,\"label\":\"SKILL\"},{\"start\":65,\"end\":71,\"token_start\":11,\"token_end\":11,\"label\":\"SKILL\"},{\"start\":89,\"end\":105,\"token_start\":16,\"token_end\":17,\"label\":\"SKILL\"},{\"start\":142,\"end\":152,\"token_start\":24,\"token_end\":24,\"label\":\"SKILL\"},{\"start\":157,\"end\":159,\"token_start\":26,\"token_end\":26,\"label\":\"SKILL\"}]},\n",
    "    {\"text\":\"Responsibilities As a SOFTWARE DEVELOPMENT ENGINEER II you will work / collaborate with other talented engineers to build features and technologies that will affect millions of your fellow developers in the community.\",\"meta\":{\"id\":\"598569\",\"category\":\"Engineering\",\"subCategory\":\"Software Engineering\"},\"_input_hash\":-930202924,\"_task_hash\":547318084,\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\",\"dataset\":1,\"tokens\":[{\"text\":\"Responsibilities\",\"start\":0,\"end\":16,\"id\":0},{\"text\":\"As\",\"start\":17,\"end\":19,\"id\":1},{\"text\":\"a\",\"start\":20,\"end\":21,\"id\":2},{\"text\":\"SOFTWARE\",\"start\":22,\"end\":30,\"id\":3},{\"text\":\"DEVELOPMENT\",\"start\":31,\"end\":42,\"id\":4},{\"text\":\"ENGINEER\",\"start\":43,\"end\":51,\"id\":5},{\"text\":\"II\",\"start\":52,\"end\":54,\"id\":6},{\"text\":\"you\",\"start\":55,\"end\":58,\"id\":7},{\"text\":\"will\",\"start\":59,\"end\":63,\"id\":8},{\"text\":\"work\",\"start\":64,\"end\":68,\"id\":9},{\"text\":\"/\",\"start\":69,\"end\":70,\"id\":10},{\"text\":\"collaborate\",\"start\":71,\"end\":82,\"id\":11},{\"text\":\"with\",\"start\":83,\"end\":87,\"id\":12},{\"text\":\"other\",\"start\":88,\"end\":93,\"id\":13},{\"text\":\"talented\",\"start\":94,\"end\":102,\"id\":14},{\"text\":\"engineers\",\"start\":103,\"end\":112,\"id\":15},{\"text\":\"to\",\"start\":113,\"end\":115,\"id\":16},{\"text\":\"build\",\"start\":116,\"end\":121,\"id\":17},{\"text\":\"features\",\"start\":122,\"end\":130,\"id\":18},{\"text\":\"and\",\"start\":131,\"end\":134,\"id\":19},{\"text\":\"technologies\",\"start\":135,\"end\":147,\"id\":20},{\"text\":\"that\",\"start\":148,\"end\":152,\"id\":21},{\"text\":\"will\",\"start\":153,\"end\":157,\"id\":22},{\"text\":\"affect\",\"start\":158,\"end\":164,\"id\":23},{\"text\":\"millions\",\"start\":165,\"end\":173,\"id\":24},{\"text\":\"of\",\"start\":174,\"end\":176,\"id\":25},{\"text\":\"your\",\"start\":177,\"end\":181,\"id\":26},{\"text\":\"fellow\",\"start\":182,\"end\":188,\"id\":27},{\"text\":\"developers\",\"start\":189,\"end\":199,\"id\":28},{\"text\":\"in\",\"start\":200,\"end\":202,\"id\":29},{\"text\":\"the\",\"start\":203,\"end\":206,\"id\":30},{\"text\":\"community\",\"start\":207,\"end\":216,\"id\":31},{\"text\":\".\",\"start\":216,\"end\":217,\"id\":32}],\"spans\":[{\"start\":22,\"end\":51,\"token_start\":3,\"token_end\":5,\"label\":\"JOB_ROLE\"},{\"start\":71,\"end\":82,\"token_start\":11,\"token_end\":11,\"label\":\"SKILL\"},{\"start\":103,\"end\":112,\"token_start\":15,\"token_end\":15,\"label\":\"JOB_ROLE\"},{\"start\":135,\"end\":147,\"token_start\":20,\"token_end\":20,\"label\":\"SKILL\"},{\"start\":189,\"end\":199,\"token_start\":28,\"token_end\":28,\"label\":\"JOB_ROLE\"}]}\n",
    "]\n",
    "\n",
    "for e in raw_examples:\n",
    "#     del e['tokens']\n",
    "    del e['_input_hash']\n",
    "    del e['_task_hash']\n",
    "#     for s in e['spans']:\n",
    "#         del s['token_start']\n",
    "#         del s['token_end']\n",
    "        \n",
    "    del_keys = [k for k in e.keys() if k not in {'text', 'spans', 'tokens'}]\n",
    "    \n",
    "    for k in del_keys:\n",
    "        del e[k]\n",
    "\n",
    "import json\n",
    "for e in raw_examples:\n",
    "    print(json.dumps(e) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple\n",
    "import spacy\n",
    "import srsly\n",
    "# import recon\n",
    "from recon.corpus import Corpus\n",
    "from recon.constants import NONE\n",
    "from recon.corrections import fix_annotations\n",
    "from recon.dataset import Dataset\n",
    "from recon.loaders import read_jsonl\n",
    "from recon.types import Example, PredictionError, HardestExample, NERStats, EntityCoverageStats, EntityCoverage, Transformation, TransformationType, OperationState\n",
    "from recon.stats import (\n",
    "    get_ner_stats, get_entity_coverage, get_sorted_type_counts, counts_to_probs, entropy,\n",
    "    calculate_entity_coverage_entropy, calculate_label_balance_entropy, calculate_label_distribution_similarity,\n",
    "    detect_outliers\n",
    ")\n",
    "import recon.tokenization as tokenization\n",
    "from recon.insights import get_ents_by_label, get_label_disparities, top_prediction_errors, top_label_disparities, get_hardest_examples\n",
    "from recon.recognizer import SpacyEntityRecognizer\n",
    "from recon.operations import registry\n",
    "from recon.store import ExampleStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('rename_labels',\n",
       "              <recon.operations.operation.__call__.<locals>.Operation at 0x7f6e34457a58>),\n",
       "             ('fix_annotations',\n",
       "              <recon.operations.operation.__call__.<locals>.Operation at 0x7f6e7e729588>),\n",
       "             ('upcase_labels',\n",
       "              <recon.operations.operation.__call__.<locals>.Operation at 0x7f6e34474240>),\n",
       "             ('filter_overlaps',\n",
       "              <recon.operations.operation.__call__.<locals>.Operation at 0x7f6e344742b0>),\n",
       "             ('fix_tokenization_and_spacing',\n",
       "              <recon.operations.operation.__call__.<locals>.Operation at 0x7f6e2fe527b8>),\n",
       "             ('add_tokens',\n",
       "              <recon.operations.operation.__call__.<locals>.Operation at 0x7f6e2fe52978>)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.operations.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_tokenization_and_spacing = registry.operations.get(\"fix_tokenization_and_spacing\")\n",
    "add_tokens = registry.operations.get(\"add_tokens\")\n",
    "rename_labels = registry.operations.get(\"rename_labels\")\n",
    "fix_annotations = registry.operations.get(\"fix_annotations\")\n",
    "upcase_labels = registry.operations.get(\"upcase_labels\")\n",
    "filter_overlaps = registry.operations.get(\"filter_overlaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recon.operations.operation.__call__.<locals>.Operation at 0x7f6e2fe527b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_tokenization_and_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus.from_disk(\"./data/skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"SKILL\": \"SKILL2\"\n",
    "}\n",
    "\n",
    "corpus.pipe_([\"fix_tokenization_and_spacing\", \"add_tokens\", \"upcase_labels\", \"filter_overlaps\", OperationState(name=\"rename_labels\", args=[label_map])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_examples\":105,\n",
      "    \"n_examples_no_entities\":29,\n",
      "    \"n_annotations\":238,\n",
      "    \"n_annotations_per_type\":{\n",
      "        \"SKILL2\":194,\n",
      "        \"PRODUCT\":34,\n",
      "        \"JOB_ROLE\":10\n",
      "    },\n",
      "    \"examples_with_type\":null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(corpus.apply(get_ner_stats, serialize=True).train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OperationState(name='fix_tokenization_and_spacing', args=[], kwargs={}, status=<OperationStatus.COMPLETED: 'COMPLETED'>, ts=datetime.datetime(2020, 4, 11, 17, 10, 20, 543871), examples_added=0, examples_removed=1, examples_changed=1, transformations=[Transformation(prev_example=1451678478863250847, example=None, type=<TransformationType.EXAMPLE_REMOVED: 'EXAMPLE_REMOVED'>), Transformation(prev_example=1125486272150827930, example=1854595451341128659, type=<TransformationType.EXAMPLE_CHANGED: 'EXAMPLE_CHANGED'>)])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(filter_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.apply_(upcase_labels)\n",
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OperationState(name='upcase_labels', args=[], kwargs={}, status=<OperationStatus.COMPLETED: 'COMPLETED'>, ts=datetime.datetime(2020, 4, 11, 17, 10, 20, 543871), examples_added=0, examples_removed=0, examples_changed=1, transformations=[Transformation(prev_example=507737641183946593, example=2270510152057565734, type=<TransformationType.EXAMPLE_CHANGED: 'EXAMPLE_CHANGED'>)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._test.operations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_disk('./fixed_data/skills', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = Corpus.from_disk('./fixed_data/skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'model'}, 'dev': set(), 'test': set(), 'all': {'model'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2.apply(get_label_disparities, \"SKILL\", \"JOB_ROLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running operation on train\n",
      "====================================================================================================\n",
      "model in corrections\n",
      "before SKILL\n",
      "after SKILL\n",
      "model in corrections\n",
      "before JOB_ROLE\n",
      "after SKILL\n",
      "TRANSFORMATIONS CALCULATED\n",
      "Transformations (ADDED):  0\n",
      "Transformations (REMOVED):  0\n",
      "Transformations (CHANGED):  1\n",
      "Running operation on dev\n",
      "====================================================================================================\n",
      "TRANSFORMATIONS CALCULATED\n",
      "Transformations (ADDED):  0\n",
      "Transformations (REMOVED):  0\n",
      "Transformations (CHANGED):  0\n",
      "Running operation on test\n",
      "====================================================================================================\n",
      "TRANSFORMATIONS CALCULATED\n",
      "Transformations (ADDED):  0\n",
      "Transformations (REMOVED):  0\n",
      "Transformations (CHANGED):  0\n"
     ]
    }
   ],
   "source": [
    "corpus2.apply_(fix_annotations, {\"model\": \"SKILL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fix_tokenization_and_spacing', 'add_tokens', 'fix_annotations']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[op.name for op in corpus2._train.operations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2.to_disk('./fixed_data/skills_2', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled operations:  set()\n",
      "Disabled operations:  set()\n",
      "Disabled operations:  set()\n"
     ]
    }
   ],
   "source": [
    "large_corpus = Corpus.from_disk(\"../../CognitiveServices/API-TextAnalytics-NER.CloudServices/data/2020-03-17/cs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.apply_(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus_dev = Dataset(\"dev\").from_disk(\"../../CognitiveServices/API-TextAnalytics-NER.CloudServices/data/2020-03-17/cs/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus_dev.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2311 - 2232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus_dev = Dataset(\"dev\").from_disk(\"../../CognitiveServices/API-TextAnalytics-NER.CloudServices/data/2020-03-17/cs/dev.jsonl\")\n",
    "lc_dev_data = large_corpus_dev.data[:1000]\n",
    "prev_data = copy.deepcopy(lc_dev_data)\n",
    "prev_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = tokenization.fix_tokenization_and_spacing(prev_data)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "print(\"RUNNING OPERATION\\n\")\n",
    "\n",
    "start = timer()\n",
    "\n",
    "initial_len = len(prev_data)\n",
    "new_data_len = len(new_data)\n",
    "\n",
    "def get_examples_and_texts(data: List[Example]) -> Tuple[Dict[int, int], Dict[str, int]]:\n",
    "    examples: Dict[int, int] = {}\n",
    "    texts: Dict[str, int] = {}\n",
    "\n",
    "    for i, e in enumerate(data):\n",
    "        examples[hash(e)] = i\n",
    "        texts[e.text_hash()] = i\n",
    "\n",
    "    return examples, texts\n",
    "\n",
    "prev_example_hashes, prev_texts = get_examples_and_texts(prev_data)\n",
    "new_example_hashes, new_texts = get_examples_and_texts(new_data)\n",
    "\n",
    "prev_diff = set(prev_example_hashes).difference(set(new_example_hashes))\n",
    "next_diff = set(new_example_hashes).difference(set(prev_example_hashes))\n",
    "\n",
    "prev_examples_to_hashes = {prev_example_hashes[pd]: pd for pd in prev_diff}\n",
    "next_examples_to_hashes = {new_example_hashes[nd]: nd for nd in next_diff}\n",
    "\n",
    "examples_added = max(len(next_diff) - len(prev_diff), 0)\n",
    "examples_removed = max(len(prev_diff) - len(next_diff), 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seen = set()\n",
    "transformations = set()\n",
    "\n",
    "for pd in prev_diff:\n",
    "    if pd in new_example_hashes:\n",
    "        prev_example_index = prev_example_hashes[pd]\n",
    "        new_example_hashes[pd] = prev_example_index\n",
    "    prev_example_index = prev_example_hashes[pd]\n",
    "    if prev_example_index in next_examples_to_hashes:\n",
    "        new_example_hash = next_examples_to_hashes[prev_example_index]\n",
    "        transformation = Transformation(prev_example=pd, example=new_example_hash, type=TransformationType.EXAMPLE_CHANGED)\n",
    "    else:\n",
    "        transformation = Transformation(prev_example=pd, example=-1, type=TransformationType.EXAMPLE_REMOVED)\n",
    "    \n",
    "    if pd not in seen and new_example_hash not in seen:\n",
    "        transformations.add(transformation)\n",
    "        seen.add(pd)\n",
    "        seen.add(new_example_hash)\n",
    "\n",
    "# seen = set()\n",
    "\n",
    "for nd in next_diff:\n",
    "    next_example_index = new_example_hashes[nd]\n",
    "    if next_example_index in prev_examples_to_hashes:\n",
    "        prev_example_hash = prev_examples_to_hashes[next_example_index]\n",
    "        transformation = Transformation(prev_example=prev_example_hash, example=nd, type=TransformationType.EXAMPLE_CHANGED)\n",
    "    else:\n",
    "        transformation = Transformation(prev_example=-1, example=nd, type=TransformationType.EXAMPLE_ADDED)\n",
    "        \n",
    "    if nd not in seen and prev_example_hash not in seen:\n",
    "        transformations.add(transformation)\n",
    "        seen.add(nd)\n",
    "        seen.add(prev_example_hash)\n",
    "\n",
    "        \n",
    "print(prev_diff)\n",
    "print(next_diff)\n",
    "print(\"Examples Added: \", examples_added)\n",
    "print(\"Examples Removed: \", examples_removed)\n",
    "print(\"Transformations: \", len(transformations))\n",
    "print(\"Transformations (ADDED): \", len([t for t in transformations if t.type == TransformationType.EXAMPLE_ADDED]))\n",
    "print(\"Transformations (REMOVED): \", len([t for t in transformations if t.type == TransformationType.EXAMPLE_REMOVED]))\n",
    "print(\"Transformations (CHANGED): \", len([t for t in transformations if t.type == TransformationType.EXAMPLE_CHANGED]))\n",
    "\n",
    "\n",
    "\n",
    "mutual_diff = set(prev_example_hashes) ^ set(new_example_hashes)\n",
    "end = timer()\n",
    "print(\"Total operation calculation time: \", round(end - start, 2))\n",
    "\n",
    "\n",
    "# from dictdiffer import diff\n",
    "# start = timer()\n",
    "# hash_diff = list(diff(prev_data, new_data))\n",
    "# end = timer()\n",
    "\n",
    "# print(\"Total diff of examples: \", round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hash_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hash_diff[0][2][0].json())\n",
    "hash_diff[0][2][1].json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([d for d in hash_diff if d[0] == \"remove\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.example_store, large_corpus._train.example_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hash(corpus._train), hash(corpus._dev), hash(corpus._test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hash(large_corpus._train), hash(large_corpus._dev), hash(large_corpus._test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hash(corpus._train)\n",
    "%timeit hash(large_corpus._train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(hash(corpus._train.data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash(corpus._train.data[0].spans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus._train.commit_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus._train.operations = []\n",
    "corpus._train.global_state = {}\n",
    "corpus._dev.operations = []\n",
    "corpus._dev.global_state = {}\n",
    "corpus._test.operations = []\n",
    "corpus._test.global_state = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_disk('./fixed_data/skills', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./fixed_data/skills/.recon/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

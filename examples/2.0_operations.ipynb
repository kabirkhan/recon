{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_examples = [\n",
    "    {\"text\":\"Have you used the new version of my model?\",\"spans\":[{\"start\":36,\"end\":41,\"token_start\":8,\"token_end\":8,\"label\":\"SKILL\"}],\"_input_hash\":1798863398,\"_task_hash\":1273875979,\"tokens\":[{\"text\":\"Have\",\"start\":0,\"end\":4,\"id\":0},{\"text\":\"you\",\"start\":5,\"end\":8,\"id\":1},{\"text\":\"used\",\"start\":9,\"end\":13,\"id\":2},{\"text\":\"the\",\"start\":14,\"end\":17,\"id\":3},{\"text\":\"new\",\"start\":18,\"end\":21,\"id\":4},{\"text\":\"version\",\"start\":22,\"end\":29,\"id\":5},{\"text\":\"of\",\"start\":30,\"end\":32,\"id\":6},{\"text\":\"my\",\"start\":33,\"end\":35,\"id\":7},{\"text\":\"model\",\"start\":36,\"end\":41,\"id\":8},{\"text\":\"?\",\"start\":41,\"end\":42,\"id\":9}],\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\"},\n",
    "    {\"text\":\"I'd like to work as an actor or model if possible.\",\"spans\":[{\"text\":\"actor\",\"start\":23,\"end\":28,\"token_start\":7,\"token_end\":7,\"label\":\"JOB_ROLE\"},{\"text\":\"model\",\"start\":32,\"end\":37,\"token_start\":9,\"token_end\":9,\"label\":\"JOB_ROLE\"}],\"_input_hash\":895552771,\"_task_hash\":-936257555,\"tokens\":[{\"text\":\"I\",\"start\":0,\"end\":1,\"id\":0},{\"text\":\"'d\",\"start\":1,\"end\":3,\"id\":1},{\"text\":\"like\",\"start\":4,\"end\":8,\"id\":2},{\"text\":\"to\",\"start\":9,\"end\":11,\"id\":3},{\"text\":\"work\",\"start\":12,\"end\":16,\"id\":4},{\"text\":\"as\",\"start\":17,\"end\":19,\"id\":5},{\"text\":\"an\",\"start\":20,\"end\":22,\"id\":6},{\"text\":\"actor\",\"start\":23,\"end\":28,\"id\":7},{\"text\":\"or\",\"start\":29,\"end\":31,\"id\":8},{\"text\":\"model\",\"start\":32,\"end\":37,\"id\":9},{\"text\":\"if\",\"start\":38,\"end\":40,\"id\":10},{\"text\":\"possible\",\"start\":41,\"end\":49,\"id\":11},{\"text\":\".\",\"start\":49,\"end\":50,\"id\":12}],\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\"},\n",
    "    {\"text\":\"We are looking for a Software Development Engineer who has solid coding skills, a strong machine learning background, and is passionate about developing new AI products.\",\"meta\":{\"id\":\"599073\",\"category\":\"Engineering\",\"subCategory\":\"Data & Applied Sciences\"},\"_input_hash\":-275722772,\"_task_hash\":868828486,\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\",\"dataset\":1,\"tokens\":[{\"text\":\"We\",\"start\":0,\"end\":2,\"id\":0},{\"text\":\"are\",\"start\":3,\"end\":6,\"id\":1},{\"text\":\"looking\",\"start\":7,\"end\":14,\"id\":2},{\"text\":\"for\",\"start\":15,\"end\":18,\"id\":3},{\"text\":\"a\",\"start\":19,\"end\":20,\"id\":4},{\"text\":\"Software\",\"start\":21,\"end\":29,\"id\":5},{\"text\":\"Development\",\"start\":30,\"end\":41,\"id\":6},{\"text\":\"Engineer\",\"start\":42,\"end\":50,\"id\":7},{\"text\":\"who\",\"start\":51,\"end\":54,\"id\":8},{\"text\":\"has\",\"start\":55,\"end\":58,\"id\":9},{\"text\":\"solid\",\"start\":59,\"end\":64,\"id\":10},{\"text\":\"coding\",\"start\":65,\"end\":71,\"id\":11},{\"text\":\"skills\",\"start\":72,\"end\":78,\"id\":12},{\"text\":\",\",\"start\":78,\"end\":79,\"id\":13},{\"text\":\"a\",\"start\":80,\"end\":81,\"id\":14},{\"text\":\"strong\",\"start\":82,\"end\":88,\"id\":15},{\"text\":\"machine\",\"start\":89,\"end\":96,\"id\":16},{\"text\":\"learning\",\"start\":97,\"end\":105,\"id\":17},{\"text\":\"background\",\"start\":106,\"end\":116,\"id\":18},{\"text\":\",\",\"start\":116,\"end\":117,\"id\":19},{\"text\":\"and\",\"start\":118,\"end\":121,\"id\":20},{\"text\":\"is\",\"start\":122,\"end\":124,\"id\":21},{\"text\":\"passionate\",\"start\":125,\"end\":135,\"id\":22},{\"text\":\"about\",\"start\":136,\"end\":141,\"id\":23},{\"text\":\"developing\",\"start\":142,\"end\":152,\"id\":24},{\"text\":\"new\",\"start\":153,\"end\":156,\"id\":25},{\"text\":\"AI\",\"start\":157,\"end\":159,\"id\":26},{\"text\":\"products\",\"start\":160,\"end\":168,\"id\":27},{\"text\":\".\",\"start\":168,\"end\":169,\"id\":28}],\"spans\":[{\"start\":21,\"end\":50,\"token_start\":5,\"token_end\":7,\"label\":\"SKILL\"},{\"start\":65,\"end\":71,\"token_start\":11,\"token_end\":11,\"label\":\"SKILL\"},{\"start\":89,\"end\":105,\"token_start\":16,\"token_end\":17,\"label\":\"SKILL\"},{\"start\":142,\"end\":152,\"token_start\":24,\"token_end\":24,\"label\":\"SKILL\"},{\"start\":157,\"end\":159,\"token_start\":26,\"token_end\":26,\"label\":\"SKILL\"}]},\n",
    "    {\"text\":\"Responsibilities As a SOFTWARE DEVELOPMENT ENGINEER II you will work / collaborate with other talented engineers to build features and technologies that will affect millions of your fellow developers in the community.\",\"meta\":{\"id\":\"598569\",\"category\":\"Engineering\",\"subCategory\":\"Software Engineering\"},\"_input_hash\":-930202924,\"_task_hash\":547318084,\"_session_id\":None,\"_view_id\":\"ner_manual\",\"answer\":\"accept\",\"dataset\":1,\"tokens\":[{\"text\":\"Responsibilities\",\"start\":0,\"end\":16,\"id\":0},{\"text\":\"As\",\"start\":17,\"end\":19,\"id\":1},{\"text\":\"a\",\"start\":20,\"end\":21,\"id\":2},{\"text\":\"SOFTWARE\",\"start\":22,\"end\":30,\"id\":3},{\"text\":\"DEVELOPMENT\",\"start\":31,\"end\":42,\"id\":4},{\"text\":\"ENGINEER\",\"start\":43,\"end\":51,\"id\":5},{\"text\":\"II\",\"start\":52,\"end\":54,\"id\":6},{\"text\":\"you\",\"start\":55,\"end\":58,\"id\":7},{\"text\":\"will\",\"start\":59,\"end\":63,\"id\":8},{\"text\":\"work\",\"start\":64,\"end\":68,\"id\":9},{\"text\":\"/\",\"start\":69,\"end\":70,\"id\":10},{\"text\":\"collaborate\",\"start\":71,\"end\":82,\"id\":11},{\"text\":\"with\",\"start\":83,\"end\":87,\"id\":12},{\"text\":\"other\",\"start\":88,\"end\":93,\"id\":13},{\"text\":\"talented\",\"start\":94,\"end\":102,\"id\":14},{\"text\":\"engineers\",\"start\":103,\"end\":112,\"id\":15},{\"text\":\"to\",\"start\":113,\"end\":115,\"id\":16},{\"text\":\"build\",\"start\":116,\"end\":121,\"id\":17},{\"text\":\"features\",\"start\":122,\"end\":130,\"id\":18},{\"text\":\"and\",\"start\":131,\"end\":134,\"id\":19},{\"text\":\"technologies\",\"start\":135,\"end\":147,\"id\":20},{\"text\":\"that\",\"start\":148,\"end\":152,\"id\":21},{\"text\":\"will\",\"start\":153,\"end\":157,\"id\":22},{\"text\":\"affect\",\"start\":158,\"end\":164,\"id\":23},{\"text\":\"millions\",\"start\":165,\"end\":173,\"id\":24},{\"text\":\"of\",\"start\":174,\"end\":176,\"id\":25},{\"text\":\"your\",\"start\":177,\"end\":181,\"id\":26},{\"text\":\"fellow\",\"start\":182,\"end\":188,\"id\":27},{\"text\":\"developers\",\"start\":189,\"end\":199,\"id\":28},{\"text\":\"in\",\"start\":200,\"end\":202,\"id\":29},{\"text\":\"the\",\"start\":203,\"end\":206,\"id\":30},{\"text\":\"community\",\"start\":207,\"end\":216,\"id\":31},{\"text\":\".\",\"start\":216,\"end\":217,\"id\":32}],\"spans\":[{\"start\":22,\"end\":51,\"token_start\":3,\"token_end\":5,\"label\":\"JOB_ROLE\"},{\"start\":71,\"end\":82,\"token_start\":11,\"token_end\":11,\"label\":\"SKILL\"},{\"start\":103,\"end\":112,\"token_start\":15,\"token_end\":15,\"label\":\"JOB_ROLE\"},{\"start\":135,\"end\":147,\"token_start\":20,\"token_end\":20,\"label\":\"SKILL\"},{\"start\":189,\"end\":199,\"token_start\":28,\"token_end\":28,\"label\":\"JOB_ROLE\"}]}\n",
    "]\n",
    "\n",
    "for e in raw_examples:\n",
    "#     del e['tokens']\n",
    "    del e['_input_hash']\n",
    "    del e['_task_hash']\n",
    "#     for s in e['spans']:\n",
    "#         del s['token_start']\n",
    "#         del s['token_end']\n",
    "        \n",
    "    del_keys = [k for k in e.keys() if k not in {'text', 'spans', 'tokens'}]\n",
    "    \n",
    "    for k in del_keys:\n",
    "        del e[k]\n",
    "\n",
    "import json\n",
    "for e in raw_examples:\n",
    "    print(json.dumps(e) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Set, Tuple\n",
    "import spacy\n",
    "import srsly\n",
    "# import recon\n",
    "from recon.corpus import Corpus\n",
    "from recon.constants import NONE\n",
    "from recon.corrections import fix_annotations\n",
    "from recon.dataset import Dataset\n",
    "from recon.loaders import read_jsonl\n",
    "from recon.types import Correction, Example, PredictionError, HardestExample, NERStats, EntityCoverageStats, EntityCoverage, Transformation, TransformationType, OperationState\n",
    "from recon.stats import (\n",
    "    get_ner_stats, get_entity_coverage, get_sorted_type_counts, get_probs_from_counts, entropy,\n",
    "    calculate_entity_coverage_entropy, calculate_label_balance_entropy, calculate_label_distribution_similarity,\n",
    "    detect_outliers\n",
    ")\n",
    "import recon.tokenization as tokenization\n",
    "from recon.insights import get_ents_by_label, get_label_disparities, top_prediction_errors, top_label_disparities, get_hardest_examples\n",
    "from recon.recognizer import SpacyEntityRecognizer\n",
    "from recon.operations import registry\n",
    "from recon.store import ExampleStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('recon.v1.rename_labels',\n",
       "              <recon.operations.Operation at 0x7fc69fd2e940>),\n",
       "             ('recon.v1.fix_annotations',\n",
       "              <recon.operations.Operation at 0x7fc69fd2e978>),\n",
       "             ('recon.v1.strip_annotations',\n",
       "              <recon.operations.Operation at 0x7fc69cf8cc50>),\n",
       "             ('recon.v1.split_sentences',\n",
       "              <recon.operations.Operation at 0x7fc6d95a6c18>),\n",
       "             ('recon.v1.fix_tokenization_and_spacing',\n",
       "              <recon.operations.Operation at 0x7fc691de3ef0>),\n",
       "             ('recon.v1.add_tokens',\n",
       "              <recon.operations.Operation at 0x7fc691de3e48>),\n",
       "             ('recon.v1.upcase_labels',\n",
       "              <recon.operations.Operation at 0x7fc691de3f60>),\n",
       "             ('recon.v1.filter_overlaps',\n",
       "              <recon.operations.Operation at 0x7fc691de3f98>),\n",
       "             ('recon.v1.prodigy.merge_examples',\n",
       "              <recon.operations.Operation at 0x7fc6900ccbe0>)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.operations.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_tokenization_and_spacing = registry.operations.get(\"fix_tokenization_and_spacing\")\n",
    "add_tokens = registry.operations.get(\"add_tokens\")\n",
    "rename_labels = registry.operations.get(\"rename_labels\")\n",
    "fix_annotations = registry.operations.get(\"fix_annotations\")\n",
    "upcase_labels = registry.operations.get(\"upcase_labels\")\n",
    "filter_overlaps = registry.operations.get(\"filter_overlaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<recon.preprocess.SpacyPreProcessor at 0x7f2d264532b0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_tokenization_and_spacing.pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus.from_disk(\"./data/skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OperationState(name='fix_tokenization_and_spacing', batch=False, args=[], kwargs={}, status=<OperationStatus.COMPLETED: 'COMPLETED'>, ts=datetime.datetime(2020, 4, 15, 12, 45, 53, 973976), examples_added=0, examples_removed=0, examples_changed=0, transformations=[])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_examples\":106,\n",
      "    \"n_examples_no_entities\":29,\n",
      "    \"n_annotations\":243,\n",
      "    \"n_annotations_per_type\":{\n",
      "        \"SKILL\":197,\n",
      "        \"PRODUCT\":33,\n",
      "        \"JOB_ROLE\":10,\n",
      "        \"skill\":2,\n",
      "        \"product\":1\n",
      "    },\n",
      "    \"examples_with_type\":null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(get_ner_stats(corpus._train.data, serialize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon.v1.spacy <generator object Language.pipe at 0x7f2d21a9ee60>\n",
      "dict_keys([1196406995714445350, 1975826118262010565, 2208035061381934376, 1473978031617727200, 106335390642092038, 500601151867807297, 440832847742549781, 706460250993890974, 1115219443209707540, 1949519895665837812, 935299783623680754, 2163307383884749416, 403532604991006089, 440153399298716595, 2165419558369486553, 709069367829232207, 1164040277870844331, 1001820030585517207, 1520504525369429473, 1143349283593732378, 772909226859630929, 2186683589276212162, 1439246817467080996, 646205256634488830, 391054967234424417, 1069073211256351973, 1631116673795041161, 1853287415515327485, 1312008281566775001, 1850119932490491100, 2248886061479488760, 1392728192912329521, 1436426349557743173, 502406100547088088, 1280147727121249306, 1761578724182773272, 1539877667996420026, 31812586317021947, 1301439328206016166, 384384728390475553, 769173937489945255, 2288129318297025329, 1242041334273589045, 228629945225414711, 1098488717506082294, 282492229720054716, 380310756566959607, 1924565152306637272, 376684774014885964, 2304838004040464281, 103529869190846028, 1988264538232162424, 1217488862723372728, 1083422037887251876, 552794652063744234, 1991149014422385820, 1804412783475653815, 133559379123924178, 630284206817307426, 1128000514323767167, 533842790538656977, 1783218316333109775, 44327064662381491, 590102417292709537, 1328189097588562120, 1471741353434857039, 1395082368088541827, 2020857152038051220, 1515538653321808267, 2909653324313924, 1142573215943909380, 1348307833267793209, 1424011768500181956, 2183248012838820930, 802489642660632463, 1860169144513739726, 435413361717193409, 606453138874978909, 1580995208213325947, 185933608830505150, 940811210756437104, 220881773549728518, 284313563161040515, 2085769956561363246, 1765438062702589944, 1090253479434315853, 1256422104425125455, 2233857738026586523, 553002533348785626, 603521638447945005, 626642907161470527, 322564103237696284, 205403610460430855, 999682930106592044, 87620785170841013, 1398471957127296361, 1869198887032894170, 1384780638327235009, 2270385796303996220, 1209709110032413943, 176860716858529675, 1241234826570026284, 200276835658424828, 2026883444237770066, 1495583689335203153, 1995249007653203494])\n",
      "recon.v1.spacy <generator object Language.pipe at 0x7f2d217df5c8>\n",
      "dict_keys([1700529846029343910, 1442725918004243918, 1615314956284386067, 2292918397458640594, 936174842952091019, 1416495214555748544, 1470704679076406034, 416936013533939646, 102976739755988675, 328680753745285627, 1821910156486108522, 461746148819085540, 1316906644314897545, 480190416079738296, 832098851410421791, 2077939734169057805, 499328831071479316, 2095072877850172291, 1709939900352147844, 59689883316342687, 398891871713859070, 1627140869294591678, 310028046539117771, 1862984016626204930, 515420873264934608, 198250555976187584, 1674255301498414544, 2207684247935563565, 39776830632428320, 967824718652465343, 1717026350721933397, 546998027537219826, 327268413308598687, 1070784568438262286, 1191963312554833233, 283812158810932089, 1600875993361830372, 827400666469217446, 833324646184074177, 141634872600563553, 868035574974736930, 710098414400391884, 2214163065793631862, 1960217053886089487, 413733258957413667, 574101210792060298, 128584703305360341, 1229099326012548773, 152681987489235101, 1203120265425271744, 1210731897437002224, 1708971935759553743, 1082408608430937670, 1587584412664023332, 1288634136647605965, 1559990870835400553, 727956066452843778, 411021709465579531, 712627598286018477, 745384867524222597, 754114973842762845, 1250213657925559709, 1060453348244319975, 1909832121214376215, 142120949158349466, 2127651655156229446, 79606520449659671, 1201338150913378032, 883878955589494298, 1476557811892588710, 75316633542116270, 1116956250434915335, 764974836186572417, 1468246759446807473, 2112306765897272231, 2193368486573054880, 1829112984191980085, 1250450046952360826, 1634755933488298800, 1602844456389187640, 863282461614727969, 2062363953964471355, 1809453615774236214, 235578488679793708, 1501219999274819459, 1842768724828632935, 1617507151150411878, 1694156056316982174, 1416023339598949511, 1712731616395876010, 1796257318551092056, 189257385865390542, 2118382680464518054, 234444508079345572, 1335636780743303396, 687445399934304164, 1068178454877698177, 935890424003835932, 1520292643375647582, 1492858771249319517, 57842038071894975, 1425233669197905973, 1605065109739879831, 3032625132909434, 1059081288433944966, 1384780638327235009, 2270385796303996220, 1209709110032413943, 176860716858529675, 1241234826570026284])\n",
      "recon.v1.spacy <generator object Language.pipe at 0x7f2d21a9ef68>\n",
      "dict_keys([1367973413700956518, 2029160499876569560, 1607811024963276245, 489279466128008280, 1415495710082308731, 2255889546845585358, 530003636929667978, 1835925174907410759, 1041359394819446102, 861318538180278693, 583083590587376325, 105665357616818193, 1559441277659343605, 993295836099910212, 697271199090081718, 1305803167822276105, 1501964998077241217, 1983023552699738193, 131613684448168329, 1499203256596183286, 1913310551616924816, 805448350284417457, 1542760328774421006, 647271954588451270, 986139625200759836, 350516643100518264, 1076604938120777862, 2262171711793193596, 122887233971179058, 1061866805993556892, 1787769822543877726, 43799087513494440, 216202532025443194, 102509625659950763, 1005529631534994242, 1541086328188921886, 1425565207195997244, 455885524989955913, 389017461808763837, 435254507021985749, 1485603496641415809, 2260855597686721254, 2191677898864625980, 132765292597080193, 1432390711654223784, 650836541803377396, 1524192431628044429, 1598691181628504187, 1957197914153068094, 926372278586414398, 1242024804406792689, 600297596622501654, 1612138149287315133, 1452781579416233781, 991080122349479433, 611942000611137234, 896909537791521797, 1294785973424865062, 367331397880364536, 578218064576825402, 179908893921063561, 1800926667122710822, 276853797656703690, 1581244857368993418, 1978762199449998997, 226275956992877221, 1283816090281245606, 1581031192357922359, 1921383998015280342, 1242326926490269961, 999978380577142972, 6802486761397437, 1199172863138105586, 1972779204238002222, 1082706630997395533, 1737571819712865172, 58089873693865820, 717335074039265265, 1940859792894958469, 2247458127698710144, 1824060206597705914, 1070135875738874749, 2149059511880502851, 1323080716800541486, 1501301622567185490, 1698455696044143889, 749766778723534242, 4193966078694182, 750447672412097139, 961663597043273946, 1017453684411282930, 2157922784386036570, 1474272284242173255, 334900450619140659, 752986196974172619, 210946257216823596])\n"
     ]
    }
   ],
   "source": [
    "corpus.apply_(\"fix_tokenization_and_spacing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OperationState(name='fix_tokenization_and_spacing', batch=False, args=[], kwargs={}, status=<OperationStatus.COMPLETED: 'COMPLETED'>, ts=datetime.datetime(2020, 4, 15, 12, 45, 53, 973976), examples_added=0, examples_removed=0, examples_changed=0, transformations=[])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"SKILL\": \"SKILL2\"\n",
    "}\n",
    "\n",
    "corpus.pipe_([\"fix_tokenization_and_spacing\", \"add_tokens\", \"upcase_labels\", \"filter_overlaps\", OperationState(name=\"rename_labels\", args=[label_map])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_examples\":106,\n",
      "    \"n_examples_no_entities\":29,\n",
      "    \"n_annotations\":243,\n",
      "    \"n_annotations_per_type\":{\n",
      "        \"SKILL2\":199,\n",
      "        \"PRODUCT\":34,\n",
      "        \"JOB_ROLE\":10\n",
      "    },\n",
      "    \"examples_with_type\":null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(corpus.apply(get_ner_stats, serialize=True).train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OperationState(name='fix_tokenization_and_spacing', args=[], kwargs={}, status=<OperationStatus.COMPLETED: 'COMPLETED'>, ts=datetime.datetime(2020, 4, 11, 17, 10, 20, 543871), examples_added=0, examples_removed=1, examples_changed=1, transformations=[Transformation(prev_example=1451678478863250847, example=None, type=<TransformationType.EXAMPLE_REMOVED: 'EXAMPLE_REMOVED'>), Transformation(prev_example=1125486272150827930, example=1854595451341128659, type=<TransformationType.EXAMPLE_CHANGED: 'EXAMPLE_CHANGED'>)])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(filter_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.apply_(upcase_labels)\n",
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OperationState(name='upcase_labels', args=[], kwargs={}, status=<OperationStatus.COMPLETED: 'COMPLETED'>, ts=datetime.datetime(2020, 4, 11, 17, 10, 20, 543871), examples_added=0, examples_removed=0, examples_changed=1, transformations=[Transformation(prev_example=507737641183946593, example=2270510152057565734, type=<TransformationType.EXAMPLE_CHANGED: 'EXAMPLE_CHANGED'>)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus._test.operations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_disk('./fixed_data/skills', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = Corpus.from_disk('./fixed_data/skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus._train.operations), len(corpus._dev.operations), len(corpus._test.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'model'}, 'dev': set(), 'test': set(), 'all': {'model'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2.apply(get_label_disparities, \"SKILL\", \"JOB_ROLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10.]\n",
      " [11. 12. 13. 14. 15.]\n",
      " [16. 17. 18. 19. 20.]\n",
      " [21. 22. 23. 24. 25.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False,  True],\n",
       "       [False,  True, False,  True, False],\n",
       "       [ True, False,  True, False,  True],\n",
       "       [False,  True, False,  True, False],\n",
       "       [ True, False,  True, False,  True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# Create a 5 x 5 ndarray with consecutive integers from 1 to 25 (inclusive).\n",
    "# Afterwards use Boolean indexing to pick out only the odd numbers in the array\n",
    " \n",
    "# Create a 5 x 5 ndarray with consecutive integers from 1 to 25 (inclusive).\n",
    "X = np.linspace(1,25,25).reshape(5,5)\n",
    "print(X)\n",
    " \n",
    "# Use Boolean indexing to pick out only the odd numbers in the array\n",
    "X * X % 2 == 1\n",
    "# Y = X[]\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Correction(annotation='model', from_label='PRODUCT', to_label='SKILL')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corrections_from_dict(corrections_dict: Dict[str, Any]):\n",
    "    corrections: List[Correction] = []\n",
    "    for key, val in corrections_dict.items():\n",
    "        if isinstance(val, str):\n",
    "            from_label = \"ANY\"\n",
    "            to_label = val\n",
    "        elif isinstance(val, tuple):\n",
    "            from_label = val[0]\n",
    "            to_label = val[1]\n",
    "        else:\n",
    "            raise ValueError(\"Cannot parse corrections dict. Value must be either a str of the label \" +\n",
    "                             \"to change the annotation to (TO_LABEL) or a tuple of (FROM_LABEL, TO_LABEL)\")\n",
    "        corrections.append(Correction(\n",
    "            annotation=key,\n",
    "            from_label=from_label,\n",
    "            to_label=to_label\n",
    "        ))\n",
    "    return corrections\n",
    "\n",
    "corrections_from_dict({\n",
    "    \"model\": (\"PRODUCT\", \"SKILL\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-27fb01a68940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"SKILL\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus2' is not defined"
     ]
    }
   ],
   "source": [
    "corrections = [\n",
    "    Correction(text=\"\")\n",
    "]\n",
    "corpus2.apply_(fix_annotations, {\"model\": \"SKILL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fix_tokenization_and_spacing', 'add_tokens', 'fix_annotations']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[op.name for op in corpus2._train.operations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2.to_disk('./fixed_data/skills_2', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.apply_(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = tokenization.fix_tokenization_and_spacing(prev_data)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "print(\"RUNNING OPERATION\\n\")\n",
    "\n",
    "start = timer()\n",
    "\n",
    "initial_len = len(prev_data)\n",
    "new_data_len = len(new_data)\n",
    "\n",
    "def get_examples_and_texts(data: List[Example]) -> Tuple[Dict[int, int], Dict[str, int]]:\n",
    "    examples: Dict[int, int] = {}\n",
    "    texts: Dict[str, int] = {}\n",
    "\n",
    "    for i, e in enumerate(data):\n",
    "        examples[hash(e)] = i\n",
    "        texts[e.text_hash()] = i\n",
    "\n",
    "    return examples, texts\n",
    "\n",
    "prev_example_hashes, prev_texts = get_examples_and_texts(prev_data)\n",
    "new_example_hashes, new_texts = get_examples_and_texts(new_data)\n",
    "\n",
    "prev_diff = set(prev_example_hashes).difference(set(new_example_hashes))\n",
    "next_diff = set(new_example_hashes).difference(set(prev_example_hashes))\n",
    "\n",
    "prev_examples_to_hashes = {prev_example_hashes[pd]: pd for pd in prev_diff}\n",
    "next_examples_to_hashes = {new_example_hashes[nd]: nd for nd in next_diff}\n",
    "\n",
    "examples_added = max(len(next_diff) - len(prev_diff), 0)\n",
    "examples_removed = max(len(prev_diff) - len(next_diff), 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seen = set()\n",
    "transformations = set()\n",
    "\n",
    "for pd in prev_diff:\n",
    "    if pd in new_example_hashes:\n",
    "        prev_example_index = prev_example_hashes[pd]\n",
    "        new_example_hashes[pd] = prev_example_index\n",
    "    prev_example_index = prev_example_hashes[pd]\n",
    "    if prev_example_index in next_examples_to_hashes:\n",
    "        new_example_hash = next_examples_to_hashes[prev_example_index]\n",
    "        transformation = Transformation(prev_example=pd, example=new_example_hash, type=TransformationType.EXAMPLE_CHANGED)\n",
    "    else:\n",
    "        transformation = Transformation(prev_example=pd, example=-1, type=TransformationType.EXAMPLE_REMOVED)\n",
    "    \n",
    "    if pd not in seen and new_example_hash not in seen:\n",
    "        transformations.add(transformation)\n",
    "        seen.add(pd)\n",
    "        seen.add(new_example_hash)\n",
    "\n",
    "# seen = set()\n",
    "\n",
    "for nd in next_diff:\n",
    "    next_example_index = new_example_hashes[nd]\n",
    "    if next_example_index in prev_examples_to_hashes:\n",
    "        prev_example_hash = prev_examples_to_hashes[next_example_index]\n",
    "        transformation = Transformation(prev_example=prev_example_hash, example=nd, type=TransformationType.EXAMPLE_CHANGED)\n",
    "    else:\n",
    "        transformation = Transformation(prev_example=-1, example=nd, type=TransformationType.EXAMPLE_ADDED)\n",
    "        \n",
    "    if nd not in seen and prev_example_hash not in seen:\n",
    "        transformations.add(transformation)\n",
    "        seen.add(nd)\n",
    "        seen.add(prev_example_hash)\n",
    "\n",
    "        \n",
    "print(prev_diff)\n",
    "print(next_diff)\n",
    "print(\"Examples Added: \", examples_added)\n",
    "print(\"Examples Removed: \", examples_removed)\n",
    "print(\"Transformations: \", len(transformations))\n",
    "print(\"Transformations (ADDED): \", len([t for t in transformations if t.type == TransformationType.EXAMPLE_ADDED]))\n",
    "print(\"Transformations (REMOVED): \", len([t for t in transformations if t.type == TransformationType.EXAMPLE_REMOVED]))\n",
    "print(\"Transformations (CHANGED): \", len([t for t in transformations if t.type == TransformationType.EXAMPLE_CHANGED]))\n",
    "\n",
    "\n",
    "\n",
    "mutual_diff = set(prev_example_hashes) ^ set(new_example_hashes)\n",
    "end = timer()\n",
    "print(\"Total operation calculation time: \", round(end - start, 2))\n",
    "\n",
    "\n",
    "# from dictdiffer import diff\n",
    "# start = timer()\n",
    "# hash_diff = list(diff(prev_data, new_data))\n",
    "# end = timer()\n",
    "\n",
    "# print(\"Total diff of examples: \", round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hash_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hash_diff[0][2][0].json())\n",
    "hash_diff[0][2][1].json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([d for d in hash_diff if d[0] == \"remove\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus.example_store, large_corpus._train.example_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hash(corpus._train), hash(corpus._dev), hash(corpus._test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hash(large_corpus._train), hash(large_corpus._dev), hash(large_corpus._test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hash(corpus._train)\n",
    "%timeit hash(large_corpus._train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(hash(corpus._train.data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash(corpus._train.data[0].spans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus._train.commit_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus._train.operations = []\n",
    "corpus._train.global_state = {}\n",
    "corpus._dev.operations = []\n",
    "corpus._dev.global_state = {}\n",
    "corpus._test.operations = []\n",
    "corpus._test.global_state = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(fix_tokenization_and_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus._train.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.apply_(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_disk('./fixed_data/skills', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./fixed_data/skills/.recon/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recon.operations import op_iter\n",
    "from recon.preprocess import SpacyPreProcessor\n",
    "from recon.registry import tokenizers\n",
    "tokenizer = tokenizers.get(\"default\")\n",
    "nlp = tokenizer()\n",
    "spacy_preprocessor = SpacyPreProcessor(nlp)\n",
    "\n",
    "\n",
    "def test_add_tokens():\n",
    "    # fmt: off\n",
    "    untokenized_examples = [Example(**example) for example in [\n",
    "        {\"text\": \"Have you used the new version of my model?\", \"spans\": [{\"start\": 36, \"end\": 41, \"label\": \"SKILL\"}]},\n",
    "        {\"text\": \"I'd like to work as an actor or model if possible.\", \"spans\": [{\"text\": \"actor\", \"start\": 23, \"end\": 28, \"label\": \"JOB_ROLE\"}, {\"text\": \"model\", \"start\": 32, \"end\": 37, \"label\": \"JOB_ROLE\"}]},\n",
    "        {\"text\": \"We are looking for a Software Development Engineer who has solid coding skills, a strong machine learning background, and is passionate about developing new AI products.\", \"spans\": [{\"start\": 21, \"end\": 50, \"label\": \"SKILL\"}, {\"start\": 65, \"end\": 71, \"label\": \"SKILL\"}, {\"start\": 89, \"end\": 105, \"label\": \"SKILL\"}, {\"start\": 142, \"end\": 152, \"label\": \"SKILL\"}, {\"start\": 157, \"end\": 159, \"label\": \"SKILL\"}]},\n",
    "        {\"text\": \"Responsibilities As a SOFTWARE DEVELOPMENT ENGINEER II you will work / collaborate with other talented engineers to build features and technologies that will affect millions of your fellow developers in the community.\", \"spans\": [{\"start\": 22, \"end\": 51, \"label\": \"JOB_ROLE\"}, {\"start\": 71, \"end\": 82, \"label\": \"SKILL\"}, {\"start\": 103, \"end\": 112, \"label\": \"JOB_ROLE\"}, {\"start\": 135, \"end\": 147, \"label\": \"SKILL\"}, {\"start\": 189, \"end\": 199, \"label\": \"JOB_ROLE\"}]}\n",
    "    ]]\n",
    "\n",
    "    tokenized_examples = [Example(**example) for example in [\n",
    "        {\"text\": \"Have you used the new version of my model?\", \"spans\": [{\"start\": 36, \"end\": 41, \"token_start\": 8, \"token_end\": 8, \"label\": \"SKILL\"}], \"tokens\": [{\"text\": \"Have\", \"start\": 0, \"end\": 4, \"id\": 0}, {\"text\": \"you\", \"start\": 5, \"end\": 8, \"id\": 1}, {\"text\": \"used\", \"start\": 9, \"end\": 13, \"id\": 2}, {\"text\": \"the\", \"start\": 14, \"end\": 17, \"id\": 3}, {\"text\": \"new\", \"start\": 18, \"end\": 21, \"id\": 4}, {\"text\": \"version\", \"start\": 22, \"end\": 29, \"id\": 5}, {\"text\": \"of\", \"start\": 30, \"end\": 32, \"id\": 6}, {\"text\": \"my\", \"start\": 33, \"end\": 35, \"id\": 7}, {\"text\": \"model\", \"start\": 36, \"end\": 41, \"id\": 8}, {\"text\": \"?\", \"start\": 41, \"end\": 42, \"id\": 9}]},\n",
    "        {\"text\": \"I'd like to work as an actor or model if possible.\", \"spans\": [{\"text\": \"actor\", \"start\": 23, \"end\": 28, \"token_start\": 7, \"token_end\": 7, \"label\": \"JOB_ROLE\"}, {\"text\": \"model\", \"start\": 32, \"end\": 37, \"token_start\": 9, \"token_end\": 9, \"label\": \"JOB_ROLE\"}], \"tokens\": [{\"text\": \"I\", \"start\": 0, \"end\": 1, \"id\": 0}, {\"text\": \"'d\", \"start\": 1, \"end\": 3, \"id\": 1}, {\"text\": \"like\", \"start\": 4, \"end\": 8, \"id\": 2}, {\"text\": \"to\", \"start\": 9, \"end\": 11, \"id\": 3}, {\"text\": \"work\", \"start\": 12, \"end\": 16, \"id\": 4}, {\"text\": \"as\", \"start\": 17, \"end\": 19, \"id\": 5}, {\"text\": \"an\", \"start\": 20, \"end\": 22, \"id\": 6}, {\"text\": \"actor\", \"start\": 23, \"end\": 28, \"id\": 7}, {\"text\": \"or\", \"start\": 29, \"end\": 31, \"id\": 8}, {\"text\": \"model\", \"start\": 32, \"end\": 37, \"id\": 9}, {\"text\": \"if\", \"start\": 38, \"end\": 40, \"id\": 10}, {\"text\": \"possible\", \"start\": 41, \"end\": 49, \"id\": 11}, {\"text\": \".\", \"start\": 49, \"end\": 50, \"id\": 12}]},\n",
    "        {\"text\": \"We are looking for a Software Development Engineer who has solid coding skills, a strong machine learning background, and is passionate about developing new AI products.\", \"tokens\": [{\"text\": \"We\", \"start\": 0, \"end\": 2, \"id\": 0}, {\"text\": \"are\", \"start\": 3, \"end\": 6, \"id\": 1}, {\"text\": \"looking\", \"start\": 7, \"end\": 14, \"id\": 2}, {\"text\": \"for\", \"start\": 15, \"end\": 18, \"id\": 3}, {\"text\": \"a\", \"start\": 19, \"end\": 20, \"id\": 4}, {\"text\": \"Software\", \"start\": 21, \"end\": 29, \"id\": 5}, {\"text\": \"Development\", \"start\": 30, \"end\": 41, \"id\": 6}, {\"text\": \"Engineer\", \"start\": 42, \"end\": 50, \"id\": 7}, {\"text\": \"who\", \"start\": 51, \"end\": 54, \"id\": 8}, {\"text\": \"has\", \"start\": 55, \"end\": 58, \"id\": 9}, {\"text\": \"solid\", \"start\": 59, \"end\": 64, \"id\": 10}, {\"text\": \"coding\", \"start\": 65, \"end\": 71, \"id\": 11}, {\"text\": \"skills\", \"start\": 72, \"end\": 78, \"id\": 12}, {\"text\": \",\", \"start\": 78, \"end\": 79, \"id\": 13}, {\"text\": \"a\", \"start\": 80, \"end\": 81, \"id\": 14}, {\"text\": \"strong\", \"start\": 82, \"end\": 88, \"id\": 15}, {\"text\": \"machine\", \"start\": 89, \"end\": 96, \"id\": 16}, {\"text\": \"learning\", \"start\": 97, \"end\": 105, \"id\": 17}, {\"text\": \"background\", \"start\": 106, \"end\": 116, \"id\": 18}, {\"text\": \",\", \"start\": 116, \"end\": 117, \"id\": 19}, {\"text\": \"and\", \"start\": 118, \"end\": 121, \"id\": 20}, {\"text\": \"is\", \"start\": 122, \"end\": 124, \"id\": 21}, {\"text\": \"passionate\", \"start\": 125, \"end\": 135, \"id\": 22}, {\"text\": \"about\", \"start\": 136, \"end\": 141, \"id\": 23}, {\"text\": \"developing\", \"start\": 142, \"end\": 152, \"id\": 24}, {\"text\": \"new\", \"start\": 153, \"end\": 156, \"id\": 25}, {\"text\": \"AI\", \"start\": 157, \"end\": 159, \"id\": 26}, {\"text\": \"products\", \"start\": 160, \"end\": 168, \"id\": 27}, {\"text\": \".\", \"start\": 168, \"end\": 169, \"id\": 28}], \"spans\": [{\"start\": 21, \"end\": 50, \"token_start\": 5, \"token_end\": 7, \"label\": \"SKILL\"}, {\"start\": 65, \"end\": 71, \"token_start\": 11, \"token_end\": 11, \"label\": \"SKILL\"}, {\"start\": 89, \"end\": 105, \"token_start\": 16, \"token_end\": 17, \"label\": \"SKILL\"}, {\"start\": 142, \"end\": 152, \"token_start\": 24, \"token_end\": 24, \"label\": \"SKILL\"}, {\"start\": 157, \"end\": 159, \"token_start\": 26, \"token_end\": 26, \"label\": \"SKILL\"}]},\n",
    "        {\"text\": \"Responsibilities As a SOFTWARE DEVELOPMENT ENGINEER II you will work / collaborate with other talented engineers to build features and technologies that will affect millions of your fellow developers in the community.\", \"tokens\": [{\"text\": \"Responsibilities\", \"start\": 0, \"end\": 16, \"id\": 0}, {\"text\": \"As\", \"start\": 17, \"end\": 19, \"id\": 1}, {\"text\": \"a\", \"start\": 20, \"end\": 21, \"id\": 2}, {\"text\": \"SOFTWARE\", \"start\": 22, \"end\": 30, \"id\": 3}, {\"text\": \"DEVELOPMENT\", \"start\": 31, \"end\": 42, \"id\": 4}, {\"text\": \"ENGINEER\", \"start\": 43, \"end\": 51, \"id\": 5}, {\"text\": \"II\", \"start\": 52, \"end\": 54, \"id\": 6}, {\"text\": \"you\", \"start\": 55, \"end\": 58, \"id\": 7}, {\"text\": \"will\", \"start\": 59, \"end\": 63, \"id\": 8}, {\"text\": \"work\", \"start\": 64, \"end\": 68, \"id\": 9}, {\"text\": \"/\", \"start\": 69, \"end\": 70, \"id\": 10}, {\"text\": \"collaborate\", \"start\": 71, \"end\": 82, \"id\": 11}, {\"text\": \"with\", \"start\": 83, \"end\": 87, \"id\": 12}, {\"text\": \"other\", \"start\": 88, \"end\": 93, \"id\": 13}, {\"text\": \"talented\", \"start\": 94, \"end\": 102, \"id\": 14}, {\"text\": \"engineers\", \"start\": 103, \"end\": 112, \"id\": 15}, {\"text\": \"to\", \"start\": 113, \"end\": 115, \"id\": 16}, {\"text\": \"build\", \"start\": 116, \"end\": 121, \"id\": 17}, {\"text\": \"features\", \"start\": 122, \"end\": 130, \"id\": 18}, {\"text\": \"and\", \"start\": 131, \"end\": 134, \"id\": 19}, {\"text\": \"technologies\", \"start\": 135, \"end\": 147, \"id\": 20}, {\"text\": \"that\", \"start\": 148, \"end\": 152, \"id\": 21}, {\"text\": \"will\", \"start\": 153, \"end\": 157, \"id\": 22}, {\"text\": \"affect\", \"start\": 158, \"end\": 164, \"id\": 23}, {\"text\": \"millions\", \"start\": 165, \"end\": 173, \"id\": 24}, {\"text\": \"of\", \"start\": 174, \"end\": 176, \"id\": 25}, {\"text\": \"your\", \"start\": 177, \"end\": 181, \"id\": 26}, {\"text\": \"fellow\", \"start\": 182, \"end\": 188, \"id\": 27}, {\"text\": \"developers\", \"start\": 189, \"end\": 199, \"id\": 28}, {\"text\": \"in\", \"start\": 200, \"end\": 202, \"id\": 29}, {\"text\": \"the\", \"start\": 203, \"end\": 206, \"id\": 30}, {\"text\": \"community\", \"start\": 207, \"end\": 216, \"id\": 31}, {\"text\": \".\", \"start\": 216, \"end\": 217, \"id\": 32}], \"spans\": [{\"start\": 22, \"end\": 51, \"token_start\": 3, \"token_end\": 5, \"label\": \"JOB_ROLE\"}, {\"start\": 71, \"end\": 82, \"token_start\": 11, \"token_end\": 11, \"label\": \"SKILL\"}, {\"start\": 103, \"end\": 112, \"token_start\": 15, \"token_end\": 15, \"label\": \"JOB_ROLE\"}, {\"start\": 135, \"end\": 147, \"token_start\": 20, \"token_end\": 20, \"label\": \"SKILL\"}, {\"start\": 189, \"end\": 199, \"token_start\": 28, \"token_end\": 28, \"label\": \"JOB_ROLE\"}]}\n",
    "    ]]\n",
    "    # fmt: on\n",
    "    \n",
    "    fixed_examples = []\n",
    "    for orig_example_hash, example, preprocessed_outputs in op_iter(untokenized_examples, pre=[spacy_preprocessor]):\n",
    "#         print(preprocessed_outputs)\n",
    "        fixed_examples.append(tokenization.add_tokens(example, preprocessed_outputs=preprocessed_outputs))\n",
    "\n",
    "    for fixed_example, tokenized_example in zip(fixed_examples, tokenized_examples):\n",
    "        assert fixed_example.text == tokenized_example.text\n",
    "        assert fixed_example.spans == tokenized_example.spans\n",
    "        assert fixed_example.tokens == tokenized_example.tokens\n",
    "        \n",
    "test_add_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "from recon.dataset import Dataset\n",
    "from pydantic import root_validator\n",
    "from recon.types import Example, Span, Token\n",
    "import numpy as np\n",
    "from recon.augmentation import augment_example\n",
    "from recon.operations import operation, registry\n",
    "from recon.preprocess import SpacyPreProcessor\n",
    "\n",
    "import names\n",
    "from snorkel.augmentation import transformation_function\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from recon.preprocess import SpacyPreProcessor\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_spans(example: Example, span_subs: Dict[Span, str]) -> Example:\n",
    "    \"\"\"Substitute spans in an example. Replaces span text and alters the example text\n",
    "    and span offsets to create a valid example.\n",
    "\n",
    "    Args:\n",
    "        example (Example): Input example\n",
    "        span_subs (Dict[int, str]): Mapping of span hash to a str replacement text\n",
    "\n",
    "    Returns:\n",
    "        Example: Output example with substituted spans\n",
    "    \"\"\"\n",
    "    span_sub_start_counter = 0\n",
    "\n",
    "    new_example_text = example.text\n",
    "    new_example_spans = []\n",
    "    \n",
    "    prev_example_spans = {hash(span) for span in example.spans}\n",
    "    spans = sorted(set(list(span_subs.keys()) + example.spans), key=lambda s: s.start)\n",
    "        \n",
    "    for span in spans:\n",
    "        should_add_span = hash(span) in prev_example_spans\n",
    "        \n",
    "        prev_end = span.end\n",
    "        new_text = span.text\n",
    "\n",
    "        if span in span_subs:\n",
    "            new_text = span_subs[span]\n",
    "            new_start = span.start + span_sub_start_counter\n",
    "            new_end = new_start + len(new_text)\n",
    "\n",
    "            new_example_text = (\n",
    "                new_example_text[: span.start + span_sub_start_counter]\n",
    "                + new_text\n",
    "                + new_example_text[span.end + span_sub_start_counter :]\n",
    "            )\n",
    "\n",
    "            span.text = new_text\n",
    "            span.start = new_start\n",
    "            span.end = new_end\n",
    "            \n",
    "            span_sub_start_counter += new_end - prev_end\n",
    "        else:\n",
    "            span.start += span_sub_start_counter\n",
    "            span.end = span.start + len(new_text)\n",
    "            span_sub_start_counter = span.end - prev_end\n",
    "\n",
    "        span.text = new_text\n",
    "        \n",
    "        if should_add_span:\n",
    "            new_example_spans.append(span)\n",
    "        \n",
    "    example.text = new_example_text\n",
    "    example.spans = new_example_spans\n",
    "\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def augment_example(\n",
    "    example: Example,\n",
    "    span_f: Callable[[Span, Any], Optional[str]],\n",
    "    spans: List[Span] = None,\n",
    "    span_label: str = None,\n",
    "    **kwargs: Any,\n",
    ") -> List[Example]:\n",
    "\n",
    "    if spans is None:\n",
    "        spans = example.spans\n",
    "\n",
    "    prev_example_hash = hash(example)\n",
    "    example = example.copy(deep=True)\n",
    "    example_t = None\n",
    "\n",
    "    if span_label:\n",
    "        spans = [s for s in spans if s.label == span_label]\n",
    "\n",
    "    if spans:\n",
    "        spans_to_sub = [np.random.choice(spans)]\n",
    "\n",
    "        span_subs = {}\n",
    "        for span in spans_to_sub:\n",
    "            res = span_f(span, **kwargs)  #  type: ignore\n",
    "            if res:\n",
    "                span_subs[span] = res\n",
    "\n",
    "        if any(span_subs.values()):\n",
    "            res = substitute_spans(example, span_subs)\n",
    "            if hash(res) != prev_example_hash:\n",
    "                example_t = res.copy(deep=True)\n",
    "\n",
    "    return example_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recon_augmentation:\n",
    "    \n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from snorkel.augmentation.tf import transformation_function\n",
    "\n",
    "\n",
    "def ent_label_sub(\n",
    "    example: Example, label: str, subs: List[str]\n",
    ") -> List[Example]:\n",
    "    \n",
    "    def augmentation_f(span: Span, subs: List[str]) -> Optional[str]:\n",
    "        subs = [s for s in subs if s != span.text]\n",
    "        sub = None\n",
    "        if len(subs) > 0:\n",
    "            sub = np.random.choice(subs)\n",
    "        return sub\n",
    "\n",
    "    return augment_example(example, span_f=augmentation_f, span_label=label, subs=subs)\n",
    "\n",
    "\n",
    "replacement_names = [names.get_full_name() for _ in range(50)]\n",
    "\n",
    "\n",
    "@transformation_function()\n",
    "def person_sub(example: Example):\n",
    "    return ent_label_sub(example.copy(deep=True), label=\"PERSON\", subs=replacement_names)\n",
    "\n",
    "@transformation_function()\n",
    "def gpe_sub(example: Example):\n",
    "    return ent_label_sub(example.copy(deep=True), label=\"GPE\", subs=[\"Russia\", \"USA\", \"China\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [\n",
    "    person_sub,\n",
    "    gpe_sub\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [0, 1], [1, 0]]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from snorkel.augmentation import RandomPolicy\n",
    "\n",
    "random_policy = RandomPolicy(\n",
    "    len(tfs), sequence_length=2, n_per_original=2, keep_original=True\n",
    ")\n",
    "\n",
    "random_policy.generate_for_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from snorkel.augmentation.apply.core import BaseTFApplier\n",
    "\n",
    "\n",
    "class ReconDatasetTFApplier(BaseTFApplier):\n",
    "    \n",
    "    def __init__(self, tfs, policy, span_label: str = None, sub_prob: float = 0.5):\n",
    "        super().__init__(tfs, policy)\n",
    "        self.span_label = span_label\n",
    "        self.sub_prob = sub_prob\n",
    "    \n",
    "    def _apply_policy_to_data_point(self, x: Example) -> List[Example]:\n",
    "        \n",
    "        x_transformed = set()\n",
    "        for seq in self._policy.generate_for_example():\n",
    "            x_t = x.copy(deep=True)\n",
    "            # Handle empty sequence for `keep_original`\n",
    "            transform_applied = len(seq) == 0\n",
    "            # Apply TFs\n",
    "            for tf_idx in seq:\n",
    "                tf = self._tfs[tf_idx]                \n",
    "                x_t_or_none = tf(x_t)\n",
    "                # Update if transformation was applied\n",
    "                if x_t_or_none is not None:\n",
    "                    transform_applied = True\n",
    "                    x_t = x_t_or_none.copy(deep=True)\n",
    "            # Add example if original or transformations applied\n",
    "            if transform_applied:\n",
    "                x_transformed.add(x_t)\n",
    "        return list(x_transformed)\n",
    "\n",
    "\n",
    "    def apply(self, ds: Dataset, progress_bar: bool = True) -> Dataset:\n",
    "        \n",
    "        @operation(\"recon.v1.augment\")\n",
    "        def augment(example: Example):\n",
    "            transformed_examples = self._apply_policy_to_data_point(example)\n",
    "            return transformed_examples\n",
    "            \n",
    "        ds.apply_(\"recon.v1.augment\")\n",
    "        \n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(text='John lives in the United States', spans=[Span(text='John', start=0, end=4, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='the United States', start=14, end=31, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='Sarah lives in Germany', spans=[Span(text='Sarah', start=0, end=5, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Germany', start=15, end=22, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True)]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recon.recognizer import SpacyEntityRecognizer\n",
    "\n",
    "r = SpacyEntityRecognizer(nlp)\n",
    "\n",
    "examples = list(r.predict([\n",
    "    \"John lives in the United States\",\n",
    "    \"Sarah lives in Germany\"\n",
    "]))\n",
    "\n",
    "ds = Dataset(\"aug_test\", examples)\n",
    "ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Applying operation 'recon.v1.augment' inplace\n",
      "\u001b[38;5;2mâœ” Completed operation 'recon.v1.augment'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<recon.dataset.Dataset at 0x7f907c2185c0>"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "applier = ReconDatasetTFApplier(tfs, random_policy)\n",
    "applier.apply(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(text='Lori Schlueter lives in USA', spans=[Span(text='Lori Schlueter', start=0, end=14, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='USA', start=24, end=27, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='John lives in the United States', spans=[Span(text='John', start=0, end=4, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='the United States', start=14, end=31, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='Traci Bickel lives in USA', spans=[Span(text='Traci Bickel', start=0, end=12, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='USA', start=22, end=25, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='Adam Veloz lives in Germany', spans=[Span(text='Adam Veloz', start=0, end=10, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Germany', start=20, end=27, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True),\n",
       " Example(text='Arthur Morales lives in Russia', spans=[Span(text='Arthur Morales', start=0, end=14, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Russia', start=24, end=30, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True),\n",
       " Example(text='Sarah lives in Germany', spans=[Span(text='Sarah', start=0, end=5, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Germany', start=15, end=22, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True)]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(text='Kelley Williamson lives in China', spans=[Span(text='Kelley Williamson', start=0, end=17, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='John', start=13, end=17, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='the United States', start=15, end=32, label='GPE', token_start=3, token_end=6, kb_id=None), Span(text='China', start=27, end=32, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='William Conn lives in the United States', spans=[Span(text='William Conn', start=0, end=12, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Jordan Floyd', start=0, end=12, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='John', start=8, end=12, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='the United States', start=22, end=39, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='John lives in the United States', spans=[Span(text='John', start=0, end=4, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='the United States', start=14, end=31, label='GPE', token_start=3, token_end=6, kb_id=None)], tokens=[Token(text='John', start=0, end=4, id=0), Token(text='lives', start=5, end=10, id=1), Token(text='in', start=11, end=13, id=2), Token(text='the', start=14, end=17, id=3), Token(text='United', start=18, end=24, id=4), Token(text='States', start=25, end=31, id=5)], meta={}, formatted=True),\n",
       " Example(text='Jordan Floyd lives in USA', spans=[Span(text='Jordan Floyd', start=0, end=12, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Sarah', start=7, end=12, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='USA', start=22, end=25, label='GPE', token_start=3, token_end=4, kb_id=None), Span(text='Germany', start=18, end=25, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True),\n",
       " Example(text='James Mack lives in USA', spans=[Span(text='James Mack', start=0, end=10, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Sarah', start=5, end=10, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Germany', start=16, end=23, label='GPE', token_start=3, token_end=4, kb_id=None), Span(text='USA', start=20, end=23, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True),\n",
       " Example(text='Sarah lives in Germany', spans=[Span(text='Sarah', start=0, end=5, label='PERSON', token_start=0, token_end=1, kb_id=None), Span(text='Germany', start=15, end=22, label='GPE', token_start=3, token_end=4, kb_id=None)], tokens=[Token(text='Sarah', start=0, end=5, id=0), Token(text='lives', start=6, end=11, id=1), Token(text='in', start=12, end=14, id=2), Token(text='Germany', start=15, end=22, id=3)], meta={}, formatted=True)]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-7a7a6ca143a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_for_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Handle empty sequence for `keep_original`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransform_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "x_transformed = []\n",
    "for seq in self._policy.generate_for_example():\n",
    "    x_t = x\n",
    "    # Handle empty sequence for `keep_original`\n",
    "    transform_applied = len(seq) == 0\n",
    "    # Apply TFs\n",
    "    for tf_idx in seq:\n",
    "\n",
    "\n",
    "        if spans is None:\n",
    "            spans = example.spans\n",
    "\n",
    "        prev_example = x.copy(deep=True)\n",
    "        if self.span_label:\n",
    "            spans = [s for s in spans if s.label == self.span_label]\n",
    "        mask = mask_1d(len(spans), prob=sub_prob)\n",
    "        spans_to_sub = list(np.asarray(spans)[mask])\n",
    "\n",
    "        span_subs = {}\n",
    "        tf = self._tfs[tf_idx]\n",
    "        for span in spans_to_sub:\n",
    "            x_t_or_none = tf(span, **kwargs)  #  type: ignore\n",
    "            if x_t_or_none is not None:\n",
    "                transform_applied = True\n",
    "                span_subs[hash(span)] = res\n",
    "\n",
    "\n",
    "        x_t_or_none = tf(x_t)\n",
    "        # Update if transformation was applied\n",
    "        if x_t_or_none is not None:\n",
    "            transform_applied = True\n",
    "            x_t = x_t_or_none\n",
    "    # Add example if original or transformations applied\n",
    "    if transform_applied:\n",
    "        x_transformed.append(x_t)\n",
    "return x_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)\n",
    "\n",
    "spacy_pre = SpacyPreProcessor(nlp)\n",
    "\n",
    "# Pregenerate some random person names to replace existing ones with\n",
    "# for the transformation strategies below\n",
    "replacement_names = [names.get_full_name() for _ in range(50)]\n",
    "\n",
    "\n",
    "def make_ent_label_sub_tf(label, subs):\n",
    "    # Replace a random named entity with a different entity of the same type.\n",
    "#     @operation(f\"recon.v1.{label}_subs\", pre=[spacy_pre], augmentation=True)\n",
    "    \n",
    "    def augmentation(span: Span, subs: List[str]) -> Optional[str]:\n",
    "        subs = [s for s in subs if s != span.text]\n",
    "        sub = None\n",
    "        if len(subs) > 0:\n",
    "            sub = np.random.choice(subs)\n",
    "        return sub\n",
    "        \n",
    "    return change_ents\n",
    "\n",
    "\n",
    "change_person_ents = make_ent_label_sub_tf(\"PERSON\", names)\n",
    "change_gpe_ents = make_ent_label_sub_tf(\"GPE\", [\"Russia\", \"China\", \"Mongolia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [\n",
    "    change_person_ents,\n",
    "    change_gpe_ents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [1, 1], [0, 1]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.augmentation import RandomPolicy\n",
    "\n",
    "random_policy = RandomPolicy(\n",
    "    len(tfs), sequence_length=2, n_per_original=2, keep_original=True\n",
    ")\n",
    "\n",
    "random_policy.generate_for_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install reconner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook walks through some of the basic use cases of Recon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from recon import Dataset, get_ner_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<recon.dataset.Dataset object at 0x7faa42ca0670>\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(\"train\", verbose=True).from_disk('./data/skills')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "Name: train\n",
      "Stats: {\n",
      "    \"n_examples\": 106,\n",
      "    \"n_examples_no_entities\": 29,\n",
      "    \"n_annotations\": 243,\n",
      "    \"n_annotations_per_type\": {\n",
      "        \"SKILL\": 197,\n",
      "        \"PRODUCT\": 33,\n",
      "        \"JOB_ROLE\": 10,\n",
      "        \"skill\": 2,\n",
      "        \"product\": 1\n",
      "    },\n",
      "    \"examples_with_type\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Dataset Operations using `Dataset.apply`\n",
    "\n",
    "If we run `get_ner_stats` on the data in our Dataset, we see the same stats that are printed above. The `Dataset` `__str__` runs the `get_ner_stats` function internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_examples\": 106,\n",
      "    \"n_examples_no_entities\": 29,\n",
      "    \"n_annotations\": 243,\n",
      "    \"n_annotations_per_type\": {\n",
      "        \"SKILL\": 197,\n",
      "        \"PRODUCT\": 33,\n",
      "        \"JOB_ROLE\": 10,\n",
      "        \"skill\": 2,\n",
      "        \"product\": 1\n",
      "    },\n",
      "    \"examples_with_type\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(ds.apply(get_ner_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make in-place Dataset Corrections using `Dataset.apply_`\n",
    "It looks like we have a few instances where we had a lowercase label (maybe from some old annotations). Let's apply an operation on the dataset and modify it in-place, converting \"skill\" => \"SKILL\" and \"product\" -> \"PRODUCT\" in our examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Applying operation 'recon.v1.upcase_labels' to dataset 'train'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 106/106 [00:00<00:00, 1619.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Completed operation 'recon.v1.upcase_labels'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds.apply_(\"recon.v1.upcase_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "Name: train\n",
      "Stats: {\n",
      "    \"n_examples\": 106,\n",
      "    \"n_examples_no_entities\": 29,\n",
      "    \"n_annotations\": 243,\n",
      "    \"n_annotations_per_type\": {\n",
      "        \"SKILL\": 199,\n",
      "        \"PRODUCT\": 34,\n",
      "        \"JOB_ROLE\": 10\n",
      "    },\n",
      "    \"examples_with_type\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "If we look again at our Dataset summary, we can see that all NER annotations with the lowercase labels have been corrected. We can now save our data and use the corrected data to train a new model. This correction is really simple and if you have a consistent annotation process, one you might not need to use very often. In later notebooks you'll see examples of more advanced corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
